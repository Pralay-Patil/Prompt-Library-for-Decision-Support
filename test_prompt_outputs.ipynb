{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udccb Prompt Testing Notebook\n", "This notebook tests reusable prompts for decision support using OpenAI GPT-4 via LangChain.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Step 1: Setup\n", "import os\n", "from langchain.chat_models import ChatOpenAI\n", "from langchain.prompts import PromptTemplate\n", "from dotenv import load_dotenv\n", "\n", "load_dotenv()\n", "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n", "\n", "llm = ChatOpenAI(temperature=0.4, openai_api_key=openai_api_key, model_name=\"gpt-4\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Step 2: Load Prompt Template\n", "prompt_text = \"\"\"\n", "You are an executive assistant. Summarize the following report for the CFO.\n", "Focus on key metrics, red flags, and decisions needed.\n", "Report:\n", "{report_content}\n", "\"\"\"\n", "\n", "template = PromptTemplate(\n", "    input_variables=[\"report_content\"],\n", "    template=prompt_text\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Step 3: Sample Input\n", "sample_report = \"\"\"\n", "Q2 revenue dropped 12% compared to Q1 due to underperformance in the APAC region.\n", "Customer churn increased from 5% to 8%, mostly in the enterprise segment.\n", "Hiring freeze saved $2M but slowed down new product development.\n", "Net promoter score declined from 70 to 60.\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Step 4: Generate Response\n", "formatted_prompt = template.format(report_content=sample_report)\n", "response = llm.predict(formatted_prompt)\n", "print(response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}